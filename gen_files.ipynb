{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.dev.bea19.origin.gector.m2   B.dev.bea19.stanza.gector.trg\n",
      "A.dev.bea19.origin.gector.trg  C.dev.bea19.origin.gector.m2\n",
      "A.dev.bea19.stanza.gector.m2   C.dev.bea19.origin.gector.trg\n",
      "A.dev.bea19.stanza.gector.trg  C.dev.bea19.stanza.gector.m2\n",
      "B.dev.bea19.origin.gector.m2   C.dev.bea19.stanza.gector.trg\n",
      "B.dev.bea19.origin.gector.trg  N.dev.bea19.origin.gector.m2\n",
      "B.dev.bea19.stanza.gector.m2   N.dev.bea19.stanza.gector.m2\n"
     ]
    }
   ],
   "source": [
    "RESULTS_DIR = \"Sentence-Boundary-GECTOR/\"\n",
    "DEV_SET_LIST = ['A', 'B', 'C', 'N']\n",
    "INITIALIZATION = False\n",
    "!ls {RESULTS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/junrui/RA/errant\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: rapidfuzz>=3.4.0 in /home/junrui/anaconda3/envs/errant/lib/python3.10/site-packages (from errant==3.0.0) (3.8.1)\n",
      "Installing collected packages: errant\n",
      "  Attempting uninstall: errant\n",
      "    Found existing installation: errant 3.0.0\n",
      "    Uninstalling errant-3.0.0:\n",
      "      Successfully uninstalled errant-3.0.0\n",
      "  Running setup.py develop for errant\n",
      "Successfully installed errant-3.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INITIALIZATION:\n",
    "    for DEV_SET_ID in DEV_SET_LIST:\n",
    "        !rm -rf {RESULTS_DIR}dev_txt/{DEV_SET_ID}.dev.bea19.txt\n",
    "        !python errant/commands/rev_from_m2.py {RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.m2 -out {RESULTS_DIR}dev_txt/{DEV_SET_ID}.dev.bea19.txt\n",
    "        print('*'*50, f\"{RESULTS_DIR}dev_txt/{DEV_SET_ID}.dev.bea19.txt\", '*'*50, sep='\\n')\n",
    "        !head {RESULTS_DIR}dev_txt/{DEV_SET_ID}.dev.bea19.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INITIALIZATION:\n",
    "    for DEV_SET_ID in DEV_SET_LIST:\n",
    "        !rm -rf {RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.txt\n",
    "        !python errant/commands/corr_from_m2.py {RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.m2 -out {RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.txt\n",
    "        print('*'*50, f\"{RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.txt\", '*'*50, sep='\\n')\n",
    "        !head {RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INITIALIZATION:\n",
    "    for DEV_SET_ID in DEV_SET_LIST:\n",
    "        if DEV_SET_ID == 'N':\n",
    "            continue\n",
    "        !rm -rf {RESULTS_DIR}gp2ft_m2/{DEV_SET_ID}.outputs_N_ft_gpt2_xl_0.txt\n",
    "        !python errant/commands/corr_from_m2.py {RESULTS_DIR}gp2ft_m2/outputs_{DEV_SET_ID}_ft_gpt2_xl_0.m2 -out {RESULTS_DIR}gp2ft_m2/outputs_{DEV_SET_ID}_ft_gpt2_xl_0.txt\n",
    "        print('*'*50, f\"{RESULTS_DIR}gp2ft_m2/outputs_{DEV_SET_ID}_ft_gpt2_xl_0.txt\", '*'*50, sep='\\n')\n",
    "        !head {RESULTS_DIR}gp2ft_m2/outputs_{DEV_SET_ID}_ft_gpt2_xl_0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resources...\n",
      "2024-04-10 16:13:43 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 17.1MB/s]\n",
      "2024-04-10 16:13:43 INFO: Downloaded file to /home/junrui/stanza_resources/resources.json\n",
      "2024-04-10 16:13:44 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-04-10 16:13:44 INFO: Using device: cuda\n",
      "2024-04-10 16:13:44 INFO: Loading: tokenize\n",
      "2024-04-10 16:13:44 INFO: Loading: mwt\n",
      "2024-04-10 16:13:44 INFO: Loading: pos\n",
      "2024-04-10 16:13:44 INFO: Loading: lemma\n",
      "2024-04-10 16:13:44 INFO: Loading: constituency\n",
      "2024-04-10 16:13:45 INFO: Loading: depparse\n",
      "2024-04-10 16:13:45 INFO: Loading: sentiment\n",
      "2024-04-10 16:13:45 INFO: Loading: ner\n",
      "2024-04-10 16:13:45 INFO: Done loading processors!\n",
      "Processing parallel files...\n",
      "Loading resources...\n",
      "2024-04-10 16:16:25 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.0MB/s]\n",
      "2024-04-10 16:16:25 INFO: Downloaded file to /home/junrui/stanza_resources/resources.json\n",
      "2024-04-10 16:16:26 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-04-10 16:16:26 INFO: Using device: cuda\n",
      "2024-04-10 16:16:26 INFO: Loading: tokenize\n",
      "2024-04-10 16:16:26 INFO: Loading: mwt\n",
      "2024-04-10 16:16:26 INFO: Loading: pos\n",
      "2024-04-10 16:16:27 INFO: Loading: lemma\n",
      "2024-04-10 16:16:27 INFO: Loading: constituency\n",
      "2024-04-10 16:16:27 INFO: Loading: depparse\n",
      "2024-04-10 16:16:27 INFO: Loading: sentiment\n",
      "2024-04-10 16:16:27 INFO: Loading: ner\n",
      "2024-04-10 16:16:28 INFO: Done loading processors!\n",
      "Processing parallel files...\n",
      "Loading resources...\n",
      "2024-04-10 16:19:38 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 15.8MB/s]\n",
      "2024-04-10 16:19:38 INFO: Downloaded file to /home/junrui/stanza_resources/resources.json\n",
      "2024-04-10 16:19:39 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-04-10 16:19:39 INFO: Using device: cuda\n",
      "2024-04-10 16:19:39 INFO: Loading: tokenize\n",
      "2024-04-10 16:19:39 INFO: Loading: mwt\n",
      "2024-04-10 16:19:39 INFO: Loading: pos\n",
      "2024-04-10 16:19:39 INFO: Loading: lemma\n",
      "2024-04-10 16:19:39 INFO: Loading: constituency\n",
      "2024-04-10 16:19:40 INFO: Loading: depparse\n",
      "2024-04-10 16:19:40 INFO: Loading: sentiment\n",
      "2024-04-10 16:19:40 INFO: Loading: ner\n",
      "2024-04-10 16:19:40 INFO: Done loading processors!\n",
      "Processing parallel files...\n",
      "Loading resources...\n",
      "2024-04-10 16:22:10 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 17.9MB/s]\n",
      "2024-04-10 16:22:10 INFO: Downloaded file to /home/junrui/stanza_resources/resources.json\n",
      "2024-04-10 16:22:11 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-04-10 16:22:11 INFO: Using device: cuda\n",
      "2024-04-10 16:22:11 INFO: Loading: tokenize\n",
      "2024-04-10 16:22:11 INFO: Loading: mwt\n",
      "2024-04-10 16:22:11 INFO: Loading: pos\n",
      "2024-04-10 16:22:11 INFO: Loading: lemma\n",
      "2024-04-10 16:22:11 INFO: Loading: constituency\n",
      "2024-04-10 16:22:11 INFO: Loading: depparse\n",
      "2024-04-10 16:22:11 INFO: Loading: sentiment\n",
      "2024-04-10 16:22:12 INFO: Loading: ner\n",
      "2024-04-10 16:22:12 INFO: Done loading processors!\n",
      "Processing parallel files...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/junrui/RA/errant/errant/commands/parallel_to_m2.py\", line 90, in <module>\n",
      "    main()\n",
      "  File \"/home/junrui/RA/errant/errant/commands/parallel_to_m2.py\", line 17, in main\n",
      "    in_files = [stack.enter_context(open(i)) for i in [args.orig]+args.cor]\n",
      "  File \"/home/junrui/RA/errant/errant/commands/parallel_to_m2.py\", line 17, in <listcomp>\n",
      "    in_files = [stack.enter_context(open(i)) for i in [args.orig]+args.cor]\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'Sentence-Boundary/N.dev.bea19.stanza.txt'\n"
     ]
    }
   ],
   "source": [
    "for DEV_SET_ID in DEV_SET_LIST:\n",
    "    # !rm -rf {RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.m2\n",
    "    # !python errant/commands/parallel_to_m2.py -orig {RESULTS_DIR}A.dev.bea19.origin.txt -cor {RESULTS_DIR}A.dev.bea19.origin.t5.trg -out {RESULTS_DIR}A.dev.bea19.origin.m2\n",
    "    \n",
    "    # if DEV_SET_ID == 'N':\n",
    "    #     continue\n",
    "    !rm -rf {RESULTS_DIR}{DEV_SET_ID}.dev.bea19.stanza.gector.m2\n",
    "    !python errant/commands/parallel_to_m2.py -orig Sentence-Boundary/{DEV_SET_ID}.dev.bea19.stanza.txt -cor {RESULTS_DIR}{DEV_SET_ID}.dev.bea19.stanza.gector.trg -out {RESULTS_DIR}{DEV_SET_ID}.dev.bea19.stanza.gector.m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1166\t889\t2122\t0.5674\t0.3546\t0.5066\n",
      "==============================================\n",
      "\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1021\t645\t1723\t0.6128\t0.3721\t0.5426\n",
      "==============================================\n",
      "\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "415\t344\t776\t0.5468\t0.3484\t0.4909\n",
      "==============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for DEV_SET_ID in DEV_SET_LIST:\n",
    "    if DEV_SET_ID == 'N':\n",
    "        continue\n",
    "    !python errant/commands/compare_m2.py -hyp {RESULTS_DIR}{DEV_SET_ID}.dev.bea19.stanza.gector.m2 -ref ../prompting-gec/coling2024-results/gold_m2/{DEV_SET_ID}.dev.gold.bea19.m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resources...\n",
      "2024-04-10 16:22:14 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 14.4MB/s]\n",
      "2024-04-10 16:22:15 INFO: Downloaded file to /home/junrui/stanza_resources/resources.json\n",
      "2024-04-10 16:22:15 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-04-10 16:22:15 INFO: Using device: cuda\n",
      "2024-04-10 16:22:15 INFO: Loading: tokenize\n",
      "2024-04-10 16:22:15 INFO: Loading: mwt\n",
      "2024-04-10 16:22:16 INFO: Loading: pos\n",
      "2024-04-10 16:22:16 INFO: Loading: lemma\n",
      "2024-04-10 16:22:16 INFO: Loading: constituency\n",
      "2024-04-10 16:22:16 INFO: Loading: depparse\n",
      "2024-04-10 16:22:16 INFO: Loading: sentiment\n",
      "2024-04-10 16:22:17 INFO: Loading: ner\n",
      "2024-04-10 16:22:17 INFO: Done loading processors!\n",
      "Processing parallel files...\n"
     ]
    }
   ],
   "source": [
    "!python errant/commands/parallel_to_m2.py -orig test_gold.txt -cor test_sys.txt -out test.m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "errant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
