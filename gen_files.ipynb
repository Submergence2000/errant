{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.dev.bea19.origin.gector.m2   C.dev.bea19.origin.gector.m2\n",
      "A.dev.bea19.origin.gector.trg  C.dev.bea19.origin.gector.trg\n",
      "A.dev.bea19.stanza.gector.m2   C.dev.bea19.stanza.gector.m2\n",
      "A.dev.bea19.stanza.gector.trg  C.dev.bea19.stanza.gector.trg\n",
      "B.dev.bea19.origin.gector.m2   N.dev.bea19.origin.gector.m2\n",
      "B.dev.bea19.origin.gector.trg  N.dev.bea19.stanza.gector.m2\n",
      "B.dev.bea19.stanza.gector.trg\n"
     ]
    }
   ],
   "source": [
    "RESULTS_DIR = \"Sentence-Boundary-GECTOR/\"\n",
    "DEV_SET_LIST = ['A', 'B', 'C', 'N']\n",
    "INITIALIZATION = False\n",
    "!ls {RESULTS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/junrui/RA/errant\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: rapidfuzz>=3.4.0 in /home/junrui/anaconda3/envs/errant/lib/python3.10/site-packages (from errant==3.0.0) (3.8.1)\n",
      "Installing collected packages: errant\n",
      "  Attempting uninstall: errant\n",
      "    Found existing installation: errant 3.0.0\n",
      "    Uninstalling errant-3.0.0:\n",
      "      Successfully uninstalled errant-3.0.0\n",
      "  Running setup.py develop for errant\n",
      "Successfully installed errant-3.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INITIALIZATION:\n",
    "    for DEV_SET_ID in DEV_SET_LIST:\n",
    "        !rm -rf {RESULTS_DIR}dev_txt/{DEV_SET_ID}.dev.bea19.txt\n",
    "        !python errant/commands/rev_from_m2.py {RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.m2 -out {RESULTS_DIR}dev_txt/{DEV_SET_ID}.dev.bea19.txt\n",
    "        print('*'*50, f\"{RESULTS_DIR}dev_txt/{DEV_SET_ID}.dev.bea19.txt\", '*'*50, sep='\\n')\n",
    "        !head {RESULTS_DIR}dev_txt/{DEV_SET_ID}.dev.bea19.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INITIALIZATION:\n",
    "    for DEV_SET_ID in DEV_SET_LIST:\n",
    "        !rm -rf {RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.txt\n",
    "        !python errant/commands/corr_from_m2.py {RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.m2 -out {RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.txt\n",
    "        print('*'*50, f\"{RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.txt\", '*'*50, sep='\\n')\n",
    "        !head {RESULTS_DIR}gold_m2/{DEV_SET_ID}.dev.gold.bea19.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INITIALIZATION:\n",
    "    for DEV_SET_ID in DEV_SET_LIST:\n",
    "        if DEV_SET_ID == 'N':\n",
    "            continue\n",
    "        !rm -rf {RESULTS_DIR}gp2ft_m2/{DEV_SET_ID}.outputs_N_ft_gpt2_xl_0.txt\n",
    "        !python errant/commands/corr_from_m2.py {RESULTS_DIR}gp2ft_m2/outputs_{DEV_SET_ID}_ft_gpt2_xl_0.m2 -out {RESULTS_DIR}gp2ft_m2/outputs_{DEV_SET_ID}_ft_gpt2_xl_0.txt\n",
    "        print('*'*50, f\"{RESULTS_DIR}gp2ft_m2/outputs_{DEV_SET_ID}_ft_gpt2_xl_0.txt\", '*'*50, sep='\\n')\n",
    "        !head {RESULTS_DIR}gp2ft_m2/outputs_{DEV_SET_ID}_ft_gpt2_xl_0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resources...\n",
      "2024-04-12 17:11:26 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 17.5MB/s]\n",
      "2024-04-12 17:11:26 INFO: Downloaded file to /home/junrui/stanza_resources/resources.json\n",
      "2024-04-12 17:11:27 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-04-12 17:11:27 INFO: Using device: cuda\n",
      "2024-04-12 17:11:27 INFO: Loading: tokenize\n",
      "2024-04-12 17:11:27 INFO: Loading: mwt\n",
      "2024-04-12 17:11:27 INFO: Loading: pos\n",
      "2024-04-12 17:11:27 INFO: Loading: lemma\n",
      "2024-04-12 17:11:27 INFO: Loading: constituency\n",
      "2024-04-12 17:11:27 INFO: Loading: depparse\n",
      "2024-04-12 17:11:27 INFO: Loading: sentiment\n",
      "2024-04-12 17:11:28 INFO: Loading: ner\n",
      "2024-04-12 17:11:28 INFO: Done loading processors!\n",
      "Processing parallel files...\n",
      "Loading resources...\n",
      "2024-04-12 17:14:06 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 17.8MB/s]\n",
      "2024-04-12 17:14:06 INFO: Downloaded file to /home/junrui/stanza_resources/resources.json\n",
      "2024-04-12 17:14:07 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-04-12 17:14:07 INFO: Using device: cuda\n",
      "2024-04-12 17:14:07 INFO: Loading: tokenize\n",
      "2024-04-12 17:14:07 INFO: Loading: mwt\n",
      "2024-04-12 17:14:07 INFO: Loading: pos\n",
      "2024-04-12 17:14:07 INFO: Loading: lemma\n",
      "2024-04-12 17:14:07 INFO: Loading: constituency\n",
      "2024-04-12 17:14:08 INFO: Loading: depparse\n",
      "2024-04-12 17:14:08 INFO: Loading: sentiment\n",
      "2024-04-12 17:14:08 INFO: Loading: ner\n",
      "2024-04-12 17:14:08 INFO: Done loading processors!\n",
      "Processing parallel files...\n",
      "Loading resources...\n",
      "2024-04-12 17:17:14 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 17.3MB/s]\n",
      "2024-04-12 17:17:14 INFO: Downloaded file to /home/junrui/stanza_resources/resources.json\n",
      "2024-04-12 17:17:15 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-04-12 17:17:15 INFO: Using device: cuda\n",
      "2024-04-12 17:17:15 INFO: Loading: tokenize\n",
      "2024-04-12 17:17:15 INFO: Loading: mwt\n",
      "2024-04-12 17:17:15 INFO: Loading: pos\n",
      "2024-04-12 17:17:15 INFO: Loading: lemma\n",
      "2024-04-12 17:17:15 INFO: Loading: constituency\n",
      "2024-04-12 17:17:16 INFO: Loading: depparse\n",
      "2024-04-12 17:17:16 INFO: Loading: sentiment\n",
      "2024-04-12 17:17:16 INFO: Loading: ner\n",
      "2024-04-12 17:17:16 INFO: Done loading processors!\n",
      "Processing parallel files...\n"
     ]
    }
   ],
   "source": [
    "for DEV_SET_ID in DEV_SET_LIST:\n",
    "    # !rm -rf /home/junrui/RA/prompting-gec/coling2024-results/gold_m2/{DEV_SET_ID}.dev.gold.bea19.m2\n",
    "    # !python errant/commands/parallel_to_m2.py -orig /home/junrui/RA/prompting-gec/coling2024-results/dev_txt/{DEV_SET_ID}.dev.bea19.txt -cor /home/junrui/RA/prompting-gec/coling2024-results/gold_m2/{DEV_SET_ID}.dev.gold.bea19.txt -out /home/junrui/RA/prompting-gec/coling2024-results/gold_m2/{DEV_SET_ID}.dev.gold.bea19.m2\n",
    "    \n",
    "    if DEV_SET_ID == 'N':\n",
    "        continue\n",
    "    !python errant/commands/parallel_to_m2.py -orig Sentence-Boundary/{DEV_SET_ID}.dev.bea19.origin.txt -cor Sentence-Boundary/{DEV_SET_ID}.dev.bea19.origin.t5.trg -out Sentence-Boundary/{DEV_SET_ID}.dev.bea19.origin.m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(948, 948)\n",
      "[((1, 1), 853), ((1, 2), 43), ((2, 1), 27), ((1, 4), 5), ((1, 3), 5), ((2, 2), 5), ((3, 1), 3), ((3, 3), 2), ((5, 2), 1), ((1, 6), 1), ((3, 5), 1), ((2, 3), 1), ((5, 1), 1)]\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1173\t771\t1800\t0.6034\t0.3946\t0.5456\n",
      "==============================================\n",
      "\n",
      "(1201, 1201)\n",
      "[((1, 1), 1109), ((1, 2), 38), ((2, 1), 25), ((1, 3), 11), ((2, 2), 5), ((1, 4), 4), ((3, 1), 3), ((2, 3), 2), ((4, 1), 2), ((1, 7), 1), ((3, 3), 1)]\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "928\t614\t1575\t0.6018\t0.3708\t0.5351\n",
      "==============================================\n",
      "\n",
      "(1008, 1008)\n",
      "[((1, 1), 938), ((1, 2), 30), ((2, 1), 24), ((1, 3), 7), ((2, 2), 3), ((1, 4), 2), ((3, 1), 2), ((3, 7), 1), ((2, 3), 1)]\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "351\t332\t766\t0.5139\t0.3142\t0.456\n",
      "==============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for DEV_SET_ID in DEV_SET_LIST:\n",
    "    if DEV_SET_ID == 'N':\n",
    "        continue\n",
    "    !python errant/commands/compare_m2.py -hyp Sentence-Boundary/{DEV_SET_ID}.dev.bea19.stanza.m2 -ref ../prompting-gec/coling2024-results/gold_m2/{DEV_SET_ID}.dev.gold.bea19.m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2452&1717&4141&0.5881506356440394&0.37190960109206733&0.5268812583265289\n"
     ]
    }
   ],
   "source": [
    "# Data from each set\n",
    "TP1, FP1, FN1 = 1173, 771, 1800\n",
    "TP2, FP2, FN2 = 928, 614, 1575\n",
    "TP3, FP3, FN3 = 351, 332, 766\n",
    "\n",
    "# Total TP, FP, FN\n",
    "TP_total = TP1 + TP2 + TP3\n",
    "FP_total = FP1 + FP2 + FP3\n",
    "FN_total = FN1 + FN2 + FN3\n",
    "\n",
    "# Calculate Precision, Recall, F0.5 Score\n",
    "Precision_total = TP_total / (TP_total + FP_total)\n",
    "Recall_total = TP_total / (TP_total + FN_total)\n",
    "F0_5_total = (1 + 0.5**2) * (Precision_total * Recall_total) / (0.5**2 * Precision_total + Recall_total)\n",
    "\n",
    "results = [TP_total, FP_total, FN_total, Precision_total, Recall_total, F0_5_total]\n",
    "print(\"&\".join([str(x) for x in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resources...\n",
      "2024-04-10 16:22:14 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 14.4MB/s]\n",
      "2024-04-10 16:22:15 INFO: Downloaded file to /home/junrui/stanza_resources/resources.json\n",
      "2024-04-10 16:22:15 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-04-10 16:22:15 INFO: Using device: cuda\n",
      "2024-04-10 16:22:15 INFO: Loading: tokenize\n",
      "2024-04-10 16:22:15 INFO: Loading: mwt\n",
      "2024-04-10 16:22:16 INFO: Loading: pos\n",
      "2024-04-10 16:22:16 INFO: Loading: lemma\n",
      "2024-04-10 16:22:16 INFO: Loading: constituency\n",
      "2024-04-10 16:22:16 INFO: Loading: depparse\n",
      "2024-04-10 16:22:16 INFO: Loading: sentiment\n",
      "2024-04-10 16:22:17 INFO: Loading: ner\n",
      "2024-04-10 16:22:17 INFO: Done loading processors!\n",
      "Processing parallel files...\n"
     ]
    }
   ],
   "source": [
    "!python errant/commands/parallel_to_m2.py -orig test_gold.txt -cor test_sys.txt -out test.m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "errant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
